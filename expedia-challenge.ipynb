{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from os.path import isdir, isfile\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# for scoring predictions\n",
    "import ml_metrics as metrics\n",
    "\n",
    "# for saving models\n",
    "from joblib import dump, load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variable descs are here: http://kaushal-desai.us/expedia-recommender-system/\n",
    "# this loads the dataset from the current working directory. It can be downloaded here:\n",
    "#     https://www.kaggle.com/c/expedia-hotel-recommendations/data?select=train.csv\n",
    "\n",
    "df_full = pd.read_csv('hotel_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Separate off test data. I'm taking an unusually small fraction for testing because\n",
    "    my predictions take a long time. It's still over 100,000 records for testing.\n",
    "'''\n",
    "df_tr, df_te = train_test_split(df_full, test_size=0.01, random_state = 1)\n",
    "\n",
    "# delete df_full to free up memory\n",
    "del df_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For training purposes, I'll drop the rows with nan and non-numeric columns\n",
    "df_tr = df_tr.select_dtypes(include=np.number).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7575230\n",
      "119624\n"
     ]
    }
   ],
   "source": [
    "# Check the length of the training and testing sets\n",
    "print(len(df_tr))\n",
    "print(len(df_te))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's a lot of records. I'm going to start with a subset, hone my technique there, then go back to the larger set.\n",
    "\n",
    "I actually don't want to balance my classes here. There are rarely booked clusters, and if I balance classes in my training set, the effect this has on the model is a willingness to sacrifice some accuracy in predicting the most popular hotel clusters in exchange for a comparable increase in accuracy in prediction for the rarely booked clusters. From a business perspective (and by the metrics given in the challenge), this tradeoff does not make sense. The aim is to get as many predictions correct as possible. So the oft-booked clusters should be privileged with overrepresentation in the training set, proportionate to their overrepresentation in the booking data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70000, 21)\n",
      "(30000, 21)\n"
     ]
    }
   ],
   "source": [
    "# sample 100,000 records\n",
    "df = df_tr.sample(n=100000)\n",
    "\n",
    "# split into train and test dataframes. df is already randomized.\n",
    "tr = df.iloc[:70000,:]\n",
    "te = df.iloc[70000:,:]\n",
    "\n",
    "# reset indices\n",
    "tr = tr.reset_index(drop=True)\n",
    "te = te.reset_index(drop=True)\n",
    "\n",
    "# check shape\n",
    "print(tr.shape)\n",
    "print(te.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06165722222222222"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the most prevalent five clusters, in descending order\n",
    "top_clusters = [_ for _ in df_tr.hotel_cluster.value_counts().head().index]\n",
    "\n",
    "# Guess the top five clusters regardless of record info\n",
    "predictions = [top_clusters for i in range(len(te))]\n",
    "\n",
    "# Check guesses\n",
    "target = [[_] for _ in te[\"hotel_cluster\"]]\n",
    "metrics.mapk(target, predictions, k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This doesn't work well.\n",
    "\n",
    "The variable srch_destination_id identifies the region targeted by the search. It stands to reason that we should modify our guesses based on the clusters prevalent per location. What if I guess the top five clusters based on the search destination id?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_five(dest):\n",
    "    ''' accepts: the search target location (srch_destination_id)\n",
    "        returns: the top five (by prevalence in records) hotel clusters at the location\n",
    "        notes:   if there are fewer than five hotel_clusters, we fill out the list by\n",
    "                 repeatedly appending the first hotel cluster in the list so far.\n",
    "    '''\n",
    "    ls = [cl for cl in tr[tr.srch_destination_id==dest].hotel_cluster.value_counts().head().keys()]\n",
    "    # In case there are no hotel_clusters associated with the location, just guess the top 5 overall.\n",
    "    if len(ls)==0:\n",
    "        return([91,41,48,64,65])\n",
    "    # The score calculator expects five guesses, so fill out a shorter list.\n",
    "    while len(ls)<5:\n",
    "        ls.insert(0,ls[0])\n",
    "    return(ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chris/.local/lib/python3.5/site-packages/ipykernel_launcher.py:2: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.24062166666666665"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions\n",
    "te.pred = te['srch_destination_id'].apply(top_five)\n",
    "\n",
    "# Check guesses\n",
    "target = [[_] for _ in te[\"hotel_cluster\"]]\n",
    "metrics.mapk(target, te.pred, k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a big improvement, and we've used no machine learning yet! Let's see what we can do by incorporating some machine learning models.\n",
    "\n",
    "Before trying to get creative, I'm going to throw some models at the data: logistic regression, LDA, KNN, naive Bayes, a decision tree classifier, a neural network, and a SVM. The idea here is not to get a good prediction, but to figure out which type of model might be best employed in a more careful attempt. I'll try these models on a small subset of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "models.append(('LR', LogisticRegression(solver='liblinear', multi_class='ovr')))\n",
    "models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "models.append(('CART', DecisionTreeClassifier()))\n",
    "models.append(('NB', GaussianNB()))\n",
    "models.append(('NN', MLPClassifier(hidden_layer_sizes=(30,30), max_iter=75)))\n",
    "models.append(('SVM', SVC(gamma='auto')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample 20,000 records\n",
    "df = df_tr.sample(n=20000, random_state=1)\n",
    "\n",
    "# Split into test and train sets, and break off the target variable\n",
    "array = df.values\n",
    "X = array[:,:20]\n",
    "y = array[:,20]\n",
    "X_train, X_validation, Y_train, Y_validation = train_test_split(X, y, test_size=0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.052714285714285714 (0.004503966505838413)\n",
      "LDA: 0.06335714285714286 (0.00395187891246373)\n",
      "KNN: 0.014714285714285713 (0.003116774889895918)\n",
      "CART: 0.0725 (0.007229827671754375)\n",
      "NB: 0.05935714285714285 (0.004817591065404928)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chris/.local/lib/python3.5/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (75) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/chris/.local/lib/python3.5/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (75) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/chris/.local/lib/python3.5/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (75) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/chris/.local/lib/python3.5/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (75) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/chris/.local/lib/python3.5/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (75) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/chris/.local/lib/python3.5/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (75) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN: 0.03385714285714286 (0.00034992710611188337)\n",
      "SVM: 0.03628571428571429 (0.0010973065354098008)\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "names = []\n",
    "\n",
    "for name, model in models:\n",
    "    kfold = StratifiedKFold(n_splits=10, random_state=1, shuffle=True)\n",
    "    cv_results = cross_val_score(model, X_train, Y_train, cv=kfold, scoring='accuracy')\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    print('{}: {} ({})'.format(name, cv_results.mean(), cv_results.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like the decision tree is superior (factoring in both accuracy and time to train). I'll proceed with that.\n",
    "\n",
    "Here's the plan: I had good success predicting hotel_cluster by just choosing the top five hotel_cluster for the record's srch_destination_id. I will improve on this by using machine learning for each srch_destination_id instead of just naively selecting the top five clusters for each srch_destination_id.\n",
    "\n",
    "There are 100 hotel clusters (not all of which are represented in each srch_destination_id). To make predictions for a particular srch_destination_id, I will iterate over all hotel_cluster represented in that srch_destination_id, and create a separate decision tree model for each of these hotel clusters. The output of each decision tree will be 1 or 0 depending on whether it judges its particular hotel_cluster is represented in that record. To make a prediction for a particular record, I'll run each of the trees, and select all of the positive predictions. If there are fewer than five positive predictions, I'll fill out the rest of my five guesses from the top hotel_clusters for that srch_destination_id. If there are more than five positive predictions, I'll order them by popularity for the srch_destination_id, and take the top five in the list.\n",
    "\n",
    "There are about 33,000 unique values of srch_destination_id, and I'll be training up to 100 decision trees per srch_destination_id. This means training a lot of decision trees. I don't think I can create trees for all the records. To optimize the impact of the resources I do have, I'll order the srch_destination_id by the number of records associated with them. For example, the srch_destination_id with the most records is 8250, with about 333,000 records. That means my first 100 decision trees will cover a lot of records. Let's have a look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Percentage of records covered')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Graph the percentage of all records covered vs number of srch_destination_id covered\n",
    "\n",
    "num_records = len(df_tr)\n",
    "\n",
    "xs = [i for i in range(1,1001)]\n",
    "ys = []\n",
    "for num in df_tr.srch_destination_id.value_counts().values[:1000]:\n",
    "    if len(ys)==0:\n",
    "        ys.append(num)\n",
    "    else:\n",
    "        ys.append(ys[-1]+num)\n",
    "ys=[100*y/num_records for y in ys]\n",
    "\n",
    "plt.scatter(xs, ys, s=4)\n",
    "plt.xlabel('Number of srch_destination_id covered')\n",
    "plt.ylabel('Percentage of records covered')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Percentage of records covered')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Graph the percentage of all records covered vs number of decision tree models trained\n",
    "\n",
    "xs = []\n",
    "ys = []\n",
    "z = df_tr.srch_destination_id.value_counts()\n",
    "for i in z.index:\n",
    "    num_trees = len(df_tr[df_tr.srch_destination_id==i].hotel_cluster.unique())\n",
    "    if len(xs)==0:\n",
    "        xs.append(num_trees)\n",
    "    else:\n",
    "        xs.append(xs[-1]+num_trees)\n",
    "    if len(ys)==0:\n",
    "        ys.append(z[i])\n",
    "    else:\n",
    "        ys.append(ys[-1]+z[i])\n",
    "ys=[y/num_records for y in ys]\n",
    "\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.scatter(xs, ys, s=4)\n",
    "plt.xlabel('Number of trees')\n",
    "plt.ylabel('Percentage of records covered')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proceeding in this way, rather than training a theoretical maximum 3.3 million models, I can cover most of the records with just 20,000 or so models. As for the records not covered by decision trees, I will revert to guessing the top five clusters for that srch_destination_id. This strategy may work better than it appears at first glance, as I am using the naive top-five strategy for records unlikely to have many hotel clusters; in particular, I'm sure to guess (although not in the right order) the correct cluster for any record with a srch_destination_id with at most five associated hotel_clusters. \n",
    "\n",
    "I think there would be benefits to an ensemble approach. Given more memory, I'd create an ensemble with LDA, decision trees, and Naive Bayes. However, given more memory, I'd also create more decision trees covering more of the records. I think the marginal memory is better spent covering more records with one model, rather than covering fewer records with several models. This hypothesis could be checked on a small data set.\n",
    "\n",
    "Let's begin to organize the models. I will create a meta dictionary \"ddict\" whose keys are srch_destination_id and whose values are in turn dictionaries. These subdictionaries will have the unique hotel_cluster associated to the srch_destination_id as keys and decision tree models corresponding to those clusters as values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the dictionary to store the dictionaries of models\n",
    "ddict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A utility function to create augmented dataframes to train the individual trees (per hotel_cluster)\n",
    "# It will be used to add an indicator variable for the hotel_cluster.\n",
    "\n",
    "def cluster_indicator(cluster,i):\n",
    "    ''' accepts: a hotel_cluster and an integer\n",
    "        returns: 1 if they are equal, 0 otherwise\n",
    "    '''\n",
    "    if cluster==i: return(1)\n",
    "    return(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Train the trees. It took about 25 minutes to train about 4000 trees on my machine.\n",
    "    They start slow (since the largest ones are first).\n",
    "# '''\n",
    "\n",
    "progress = 0 # a counter used as a mechanism to break the process by user input\n",
    "\n",
    "# store the srch_destination_ids in descending order of prevalence in the full dataframe\n",
    "srch_dest_ids = df_tr.srch_destination_id.value_counts().index\n",
    "\n",
    "for n in srch_dest_ids:\n",
    "    if n in ddict.keys(): pass # check if we've already handled that srch_destination_id\n",
    "    else:\n",
    "        progress +=1\n",
    "        print('working on {}'.format(n))\n",
    "        if progress%3000==0:\n",
    "            # pause to give user the option to break. I used it to save off models, as I expected running\n",
    "            # the whole process at once would exhaust my memory\n",
    "            cont = input('Continue? y/n')\n",
    "            if cont.lower()=='n': break\n",
    "        \n",
    "        # get the subset of df_tr consisting of records with the particular srch_dest_id\n",
    "        dfr = df_tr[df_tr.srch_destination_id==n]\n",
    "\n",
    "        # initialize the subdictionary which will hold this srch_dest_id's models\n",
    "        ddict[n]={}\n",
    "        \n",
    "        # separate off the training data\n",
    "        X=dfr.values[:,:20]\n",
    "\n",
    "        # for each hotel_cluster, train a model and store it in the subdict \n",
    "        for i in dfr.hotel_cluster.unique():\n",
    "            y = dfr['hotel_cluster'].apply(cluster_indicator, args = [i])\n",
    "            X_train, X_validation, Y_train, Y_validation = train_test_split(X, y, test_size=0.3, random_state=1)\n",
    "\n",
    "            ddict[n][i]=DecisionTreeClassifier()\n",
    "            ddict[n][i].fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save models\n",
    "\n",
    "for i in ddict.keys():\n",
    "    if not os.path.isdir('saved_models/{}'.format(int(i))):\n",
    "        os.makedirs('saved_models/{}'.format(int(i)))\n",
    "    for j in ddict[i].keys():\n",
    "        if not os.path.isfile('saved_models/{}/{}.joblib'.format(int(i),int(j))):\n",
    "            dump(ddict[i][j], 'saved_models/{}/{}.joblib'.format(int(i),int(j)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load models from disk\n",
    "\n",
    "ddict = {}\n",
    "for direc in os.listdir('saved_models/'):\n",
    "    srch_dest_id = int(direc)\n",
    "    ddict[srch_dest_id]={}\n",
    "    for filename in os.listdir('saved_models/{}/'.format(direc)):\n",
    "        cluster=int(filename.split('.')[0])\n",
    "        ddict[srch_dest_id][cluster]=load('saved_models/{}/{}'.format(direc,filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what percentage of the records are covered by the models trained so far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93.3% of records are covered by models.\n"
     ]
    }
   ],
   "source": [
    "# check to see how many records are covered by the models trained so far\n",
    "tot = 0\n",
    "for id in ddict.keys():\n",
    "    tot += len(df_tr[df_tr['srch_destination_id']==id])\n",
    "print('{}% of records are covered by models.'.format(round(100*tot/num_records,1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I suppose that's good enough. Let's test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to generate predictions based on the trained models\n",
    "\n",
    "def ddict_pred(x):\n",
    "    ''' accepts: a record (with non-numerics strippedp) from the test set\n",
    "        returns: a list of five predicted hotel_clusters.\n",
    "        notes:   if the record does not have an associated decision tree,\n",
    "                 this will just return the overall top five hotel_clusters.\n",
    "                 I intended to return the top five for the record's\n",
    "                 srch_destination_id, but something was not working with it.\n",
    "    '''\n",
    "    x=x.values.reshape(1,-1)\n",
    "    if x[0][13] in ddict.keys():\n",
    "        preds = []\n",
    "        val_cts = df_tr[df_tr['srch_destination_id']==x[0][13]].hotel_cluster.value_counts()\n",
    "        for j in ddict[x[0][13]].keys():\n",
    "            try: preds.append((j,ddict[x[0][13]][j].predict(x)))\n",
    "            except: return(top_clusters)\n",
    "                #except: print('not fitted: {} in {}'.format(j,x[0][13]))\n",
    "\n",
    "        # the positive predictions\n",
    "        pred_pos = [_[0] for _ in preds if _[1]==1]\n",
    "\n",
    "        if len(pred_pos)<5:\n",
    "            # supplement the prediction list with the prevalent clusters in the search destination\n",
    "            N = len(val_cts)-1\n",
    "            count = 0\n",
    "            while len(pred_pos)<5: # goes down the list of common clusters not yet in pred_pos\n",
    "                # cycles back to the beginning if this list is less than 5-len(pred_pos) in length\n",
    "                remainder = [_ for _ in val_cts.index if _ not in pred_pos]\n",
    "                try: pred_pos.append(remainder[count%N]) # breaks if there is no remainder\n",
    "                except: # so we have all the options in pred_pos already. just append the first until length==5\n",
    "                    while len(pred_pos)<5:\n",
    "                        pred_pos.append(pred_pos[0])\n",
    "                    break\n",
    "                count+=1\n",
    "            pred_final = pred_pos\n",
    "        else:\n",
    "            # orders the predicted cluster according to their prevalence in the search destination\n",
    "            pred_final = [value for value in val_cts.index if value in pred_pos]\n",
    "            # cut to five predictions\n",
    "            pred_final = pred_final[:5]\n",
    "        return(pred_final)\n",
    "    else:\n",
    "        return(top_clusters) # TODO why is this broken, need top five.\n",
    "        #return(top_five(x[0][13]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split off the test target\n",
    "target = [[_] for _ in df_te.select_dtypes(include=np.number)[\"hotel_cluster\"]]\n",
    "\n",
    "# Drop the non-numeric columns, which I don't use for the prediction\n",
    "df_te = df_te.iloc[:,:-1].select_dtypes(include=np.number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 803,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Generate the test predictions.\n",
    "    This took two hours on my machine.\n",
    "'''\n",
    "\n",
    "te.pred = df_te.apply(ddict_pred,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 810,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model score: 0.512\n"
     ]
    }
   ],
   "source": [
    "score = metrics.mapk(target, te.pred, k=5)\n",
    "print('Model score: {}'.format(round(score,3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This is good accuracy. Unfortunately, the predicting is slow. It takes two hours to generate 100,000 predictions, so for the full test file it should take around 80 hours on my machine. It could be done, as memory was not close to running out, and would not run out for the full test file of ~4million records.\n",
    "\n",
    "Improvements which should be straightforward:\n",
    "* Feature selection.\n",
    "* Finish training models for all srch_destination_id values.\n",
    "* Take an ensemble approach with decision trees, LDA, and naive Bayes.\n",
    "* Implement calibrated classifiers to give probabilistic contexts to the classifier outputs.\n",
    "\n",
    "Unresolved issues:\n",
    "* I could not get the top_five function working within my model prediction function. Instead, I just assigned the top five overall hotel_cluster list to any srch_destination_id which did not have a model trained for it. By getting the top_five per srch_destination_id working within my model prediction, I estimate I would increase the score by 0.05 to 0.1 on my reduced test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spare code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # code for selecting balanced classes (I argued above why we shouldn't)\n",
    "\n",
    "# # how many records for each hotel cluster?\n",
    "# df_tr[df_tr.is_booking == 1].hotel_cluster.value_counts()\n",
    "\n",
    "# # verifying the unique hotel cluster values\n",
    "# df.hotel_cluster.unique()\n",
    "\n",
    "# # balance the sample on hotel_cluster. I think I can do this manually:\n",
    "# df_sample = blank dataframe\n",
    "# for each of the values in df.hotel_cluster.values():\n",
    "#    temp_dataframe = randomly sample 5000 lines from df[df.hotel_cluster==value]\n",
    "#    append temp_dataframe to df_sample\n",
    "# shuffle df_sample\n",
    "# reindex df_sample\n",
    "\n",
    "# ''' The most rarely booked cluster has 766 records. We can get a good-sized, balanced subset\n",
    "#     taking 750 records corresponding to each hotel cluster.\n",
    "# '''\n",
    "\n",
    "# # initialize the sampled dataframe\n",
    "# df = pd.DataFrame(columns=df.columns)\n",
    "\n",
    "# for i in df_tr.hotel_cluster.unique():\n",
    "#     if i==i: # I was getting nan as a value in the loop for some reason\n",
    "#         df_temp = df_tr[(df_tr.is_booking == 1)&(df_tr.hotel_cluster==i)].sample(n=750)\n",
    "#         df = df.append(df_temp)\n",
    "        \n",
    "# # the sample should only be drawn from is_booking == 1 (as the test set is like that)\n",
    "\n",
    "# # check that it worked\n",
    "# print(df.shape)\n",
    "# df.hotel_cluster.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # calibrated classifier - for improvements over just taking top 5 positive results\n",
    "# # this is how we would get the model to output probabilities instead of just 0 or 1.\n",
    "\n",
    "# from sklearn.calibration import CalibratedClassifierCV\n",
    "# base_clf = DecisionTreeClassifier()\n",
    "# calibrated_clf = CalibratedClassifierCV(base_estimator=base_clf, cv=2)\n",
    "# calibrated_clf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # For PCA\n",
    "# from sklearn import decomposition\n",
    "\n",
    "# pca = decomposition.PCA(n_components=5)\n",
    "# pca.fit(X)\n",
    "# X=pca.transform(X)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
